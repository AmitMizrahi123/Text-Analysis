{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5 - Text Analysis\n",
    "An explanation this assignment could be found in the .pdf explanation document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Materials to review for this assignment\n",
    "<h4>From Moodle:</h4> \n",
    "<h5><u>Review the notebooks regarding the following python topics</u>:</h5>\n",
    "<div class=\"alert alert-info\">\n",
    "&#x2714; <b>Working with strings</b> (tutorial notebook)<br/>\n",
    "&#x2714; <b>Text Analysis</b> (tutorial notebook)<br/>\n",
    "&#x2714; <b>Hebrew text analysis tools (tokenizer, wordnet)</b> (moodle example)<br/>\n",
    "&#x2714; <b>(brief review) All previous notebooks</b><br/>\n",
    "</div> \n",
    "<h5><u>Review the presentations regarding the following topics</u>:</h5>\n",
    "<div class=\"alert alert-info\">\n",
    "&#x2714; <b>Text Analysis</b> (lecture presentation)<br/>\n",
    "&#x2714; <b>(brief review) All other presentations</b><br/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preceding Step - import modules (packages)\n",
    "This step is necessary in order to use external modules (packages). <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# ------------- visualizations:\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "import sklearn\n",
    "from sklearn import preprocessing, metrics, pipeline, model_selection, feature_extraction \n",
    "from sklearn import naive_bayes, linear_model, svm, neural_network, neighbors, tree\n",
    "from sklearn import decomposition, cluster\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, make_scorer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, silhouette_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier, LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# ---------------------------------------\n",
    "\n",
    "\n",
    "# ----------------- output and visualizations: \n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "# show several prints in one cell. This will allow us to condence every trick in one cell.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline\n",
    "pd.pandas.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "# ---------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text analysis and String manipulation imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# --------- Text analysis and Hebrew text analysis imports:\n",
    "# vectorizers:\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# regular expressions:\n",
    "import re\n",
    "# --------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Hebrew text analysis - WordNet (for Hebrew)\n",
    "Note: the WordNet is not a must"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) Only if you didn't install Wordnet (for Hebrew) use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word net installation:\n",
    "\n",
    "# unmark if you want to use and need to install\n",
    "# !pip install wn\n",
    "# !python -m wn download omw-he:1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word net import:\n",
    "\n",
    "# unmark if you want to use:\n",
    "# import wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (optional) Hebrew text analysis - hebrew_tokenizer (Tokenizer for Hebrew)\n",
    "Note: the hebrew_tokenizer is not a must"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (optional) Only if you didn't install hebrew_tokenizer use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hebrew tokenizer installation:\n",
    "\n",
    "# unmark if you want to use and need to install:\n",
    "!pip install hebrew_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hebrew tokenizer import:\n",
    "\n",
    "# unmark if you want to use:\n",
    "import hebrew_tokenizer as ht"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading input files\n",
    "Reading input files for train annotated corpus (raw text data) corpus and for the test corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = 'annotated_corpus_for_train.csv'\n",
    "test_filename  = 'corpus_for_test.csv'\n",
    "df_train = pd.read_csv(train_filename, index_col=None, encoding='utf-8')\n",
    "df_test  = pd.read_csv(test_filename, index_col=None, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(8)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(3)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your implementation:\n",
    "Write your code solution in the following code-cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Method that remove all the unnecessary chars.\n",
    "def remove_unnecessary_chars(series):\n",
    "    preprocess_x = []\n",
    "\n",
    "    for txt in list(series):\n",
    "        txt = re.sub(r'[.,:]', '', txt) # Remove periods, commas and colons\n",
    "        txt = re.sub(r'\\b\\w\\b', '', txt)  # Removes single characters\n",
    "        txt = re.sub(r'\\s+', ' ', txt)  # Replaces multiple spaces with a single space\n",
    "        preprocess_x.append(txt)\n",
    "\n",
    "    return preprocess_x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Method that make sure that our story contain only hebrew words\n",
    "def hebrew_text(story):\n",
    "    list_of_the_tokens = []\n",
    "    all_the_tokens = ht.tokenize(story)\n",
    "\n",
    "    for grp, token, token_num, (start_index, end_index) in all_the_tokens:\n",
    "        if grp == 'HEBREW':\n",
    "            list_of_the_tokens.append(token)\n",
    "\n",
    "    return list_of_the_tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary chars from the stories by using regex\n",
    "X = remove_unnecessary_chars(df_train.story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverts gender from [m, f] to [0,1] to ignore errors when I fit the y train\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y = encoder.fit_transform(df_train.gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# settings for the running\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "class VectOptions(Enum):\n",
    "    TfidfVectorizer = 1,\n",
    "    CountVectorizer = 2\n",
    "\n",
    "class ModelOptions(Enum):\n",
    "    DecisionTreeClassifier = 1\n",
    "    KNeighborsClassifier = 2\n",
    "    MultinomialNB = 3\n",
    "\n",
    "ngram_list = [(1, 1), (1, 2), (1, 3)]\n",
    "min_df = [3, 5 ,7]\n",
    "max_features = [10000, 15000, 20000]\n",
    "scoring = make_scorer(f1_score, average='macro')\n",
    "cv = 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model options: DecisionTreeClassifier, KNeighborsClassifier and MultinomialNB\n",
    "\n",
    "def get_model_option(model_option):\n",
    "    if model_option == ModelOptions.DecisionTreeClassifier:\n",
    "        return DecisionTreeClassifier()\n",
    "    elif model_option == ModelOptions.KNeighborsClassifier:\n",
    "        return KNeighborsClassifier()\n",
    "    return MultinomialNB()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cross validation result accuracy\n",
    "\n",
    "def get_cross_validation(model, X, y):\n",
    "    f1_scores = cross_val_score(model, X, y, cv=cv)\n",
    "    return f1_scores.mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# F1 score with cross validation\n",
    "\n",
    "def get_f1_average_score(model, X, y):\n",
    "    f1_scores = cross_val_score(model, X, y, scoring=scoring, cv=cv)\n",
    "    return f1_scores.mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get results\n",
    "\n",
    "def get_results(model_option, X, y):\n",
    "    clf = get_model_option(model_option)\n",
    "    clf.fit(X, y)\n",
    "    accuracy_cross_validation = get_cross_validation(clf, X, y)\n",
    "    f1_average_score_cross_validation = get_f1_average_score(clf, X, y)\n",
    "    param_grid = get_param_grid(model_option)\n",
    "    grid_search = GridSearchCV(clf, param_grid=param_grid, scoring=scoring, cv=cv)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search_f1_average_score_cross_validation_parameters = grid_search.best_params_\n",
    "    grid_search_f1_average_score_cross_validation = grid_search.best_score_\n",
    "\n",
    "    return accuracy_cross_validation, \\\n",
    "           f1_average_score_cross_validation, \\\n",
    "           grid_search_f1_average_score_cross_validation, \\\n",
    "           grid_search_f1_average_score_cross_validation_parameters, \\\n",
    "           clf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# get the param grid by the model\n",
    "\n",
    "def get_param_grid(model_option):\n",
    "    if model_option == ModelOptions.DecisionTreeClassifier:\n",
    "        return {\n",
    "            'max_depth': [None, 5, 10, 15, 20]\n",
    "        }\n",
    "    elif model_option == ModelOptions.KNeighborsClassifier:\n",
    "        return {\n",
    "            'n_neighbors': [3, 5, 7, 9]\n",
    "        }\n",
    "    return {\n",
    "        'alpha': [1, 5, 10, 15],\n",
    "        'fit_prior': [False, True]\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create vectorizer\n",
    "\n",
    "def vectorizer(vect_option, max_feature, ngram, min_d):\n",
    "    vect = CountVectorizer(tokenizer=hebrew_text, analyzer='word', max_features=max_feature, ngram_range=ngram, min_df=min_d, decode_error='ignore')\n",
    "\n",
    "    if vect_option == VectOptions.TfidfVectorizer:\n",
    "        vect = TfidfVectorizer(tokenizer=hebrew_text, analyzer='word', max_features=max_feature, ngram_range=ngram, min_df=min_d, decode_error='ignore')\n",
    "\n",
    "    return vect"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create vectorizer and normalize\n",
    "\n",
    "def vectorizer_and_normalize(vect_option, X, max_feature, ngram, min_d):\n",
    "    vect = vectorizer(vect_option, max_feature, ngram, min_d)\n",
    "    vect.fit(X)\n",
    "    vect_X = vect.fit_transform(X)\n",
    "    vect_X = preprocessing.normalize(vect_X, norm='l2')\n",
    "\n",
    "    return vect_X, vect"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_score_f1_average = 0\n",
    "best_score_grid_search = 0\n",
    "\n",
    "for max_feature in max_features:\n",
    "    print(\"##########################################\")\n",
    "    print(f\"The max feature is {max_feature}\")\n",
    "\n",
    "    for ngram in ngram_list:\n",
    "        print(f\"The ngram is {ngram}\")\n",
    "\n",
    "        for min_d in min_df:\n",
    "            print(f\"The min dataframe is {min_d}\")\n",
    "\n",
    "            for vect_option in VectOptions:\n",
    "                print(f\"The vect option is {vect_option}\")\n",
    "\n",
    "                vect_X, vect = vectorizer_and_normalize(vect_option, X, max_feature, ngram, min_d)\n",
    "\n",
    "                for model_option in ModelOptions:\n",
    "                    print(f\"The model is {model_option}\")\n",
    "\n",
    "                    accuracy_cross_validation, \\\n",
    "                    f1_average_score_cross_validation, \\\n",
    "                    grid_search_f1_average_score_cross_validation, \\\n",
    "                    grid_search_f1_average_score_cross_validation_parameters, \\\n",
    "                    clf = get_results(model_option, vect_X, y)\n",
    "\n",
    "                    print(f\"Cross validation results accuracy: {accuracy_cross_validation}\")\n",
    "                    print(f\"Average F1 score: {f1_average_score_cross_validation}\")\n",
    "\n",
    "                    if f1_average_score_cross_validation > best_score_f1_average:\n",
    "                        best_score_f1_average = f1_average_score_cross_validation\n",
    "\n",
    "                    print(f\"F1 average macro on grid search best Score for {model_option} is {grid_search_f1_average_score_cross_validation}\")\n",
    "\n",
    "                    if grid_search_f1_average_score_cross_validation > best_score_grid_search:\n",
    "                        best_score_grid_search = grid_search_f1_average_score_cross_validation # Saving the best score\n",
    "                        best_model = clf # Saving the best model for prediction\n",
    "                        best_max_feature = max_feature # Saving the best max feature\n",
    "                        best_ngram = ngram # Saving the best ngram\n",
    "                        best_min_d = min_d # Saving the best min df\n",
    "                        best_vect = vect # Saving the best vect\n",
    "                        best_parameters = grid_search_f1_average_score_cross_validation_parameters # Saving the best parameters\n",
    "\n",
    "    print(\"##########################################\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"The best F1 average score is {best_score_f1_average}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"The best grid search score is {best_score_grid_search}, \"\n",
    "      f\"the model is {best_model} \"\n",
    "      f\"with the ngram = {best_ngram}, \"\n",
    "      f\"min_df = {best_min_d} and \"\n",
    "      f\"max_feature = {best_max_feature} \"\n",
    "      f\"best parameters = {best_parameters}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predictions = best_model.predict(best_vect.transform(df_test.story))\n",
    "df_predict = pd.DataFrame({'test_example_id': df_test.test_example_id, 'predictions': predictions})\n",
    "df_predict.head()\n",
    "df_predict.tail()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
